# August 4 2020
## Optimization
I've been stuck for three days or so trying to implement berry bushes, of all things. Implementing berry bushes, with berries that can be eaten and can regrow, is not difficult in and of itself. The difficulty has arisen from trying to learn to use the data structures library that the tutorial started me out using, NumPy.

Numpy is apparently a library used extensively in science, math, and academia. It excels at storing lots of data in arrays, matrices, and tensors, and provides methods for doing efficient operations on them. It's optimized for use with tons of data.

However, I would argue it forces one to think about data structures in a significantly different way than "normal" if, for example, you were introduced to software development via the traditional route of getting a CS degree. From what I've seen so far, if you have a n-dimensional array in Numpy and you want to get information out of it, you treat the array almost like a database and make queries. For example, imagine I have a 2D grid of map tiles where each tile has a boolean attribute "walkable". If I want to find out if a particular tile is walkable, one way to do that is to request walkable tiles from Numpy, and it will return a 2D array of booleans. So if I know the x-y coordinates of the tile I'm interested in, I can query this array at x-y to see if the boolean is true or false.

This is a strange way for me to think about 2D grids and getting information out of them. Perhaps there are other more "normal" ways to access information from Numpy, but everything I've seen so far is, at the very least, pretty awkward.

After struggling with this and mulling it over for two or three days, I've come to the conclusion that I should refactor my code away from using Numpy for now. Things sort of clicked when I had this thought: I need to optimize *my* ability to quickly do stuff, not the computer's ability to quickly do stuff. 

This is something I think about a lot in my day job. When I'm writing code professionally, my heuristic for deciding what style of coding to use is: Optimize for code readability, unless I have a *really* good reason to optimize for something else instead. To put it another way, optimize for humans first, and computers only when absolutely necessary.

I prefer to optimize for humans becasue it results in code that is generally easier for me to maintain, and it's also generally easier for my team members to understand and maintain. Many times in the past I've written some code for a project, and then 6-12 months later I have to jump back into it to fix a bug or add a new feature. It's in those moments that I most appreciate having written readable code; it makes it so much easier to figure out what the hell I was doing and why. Furthermore, it generally makes my coworkers want to throttle me less when I write easy-to-understand-and-debug code.

But when working on personal projects, there are other things to consider as well. For me, careful management of my "hype wave" is necessary for a personal project to be successful. The hype wave is strong early in a project, but a couple weeks in, for example, it may start to fade and other sources of hype must be identified and utilized.

I say all this because using Numpy is, right now, killing my hype wave, and proving to be an obstacle to progress. So instead of continuing to use it and hoping that it pays off in the (probably-distant) future, I am going to refactor away from using it, which will pay off now, when I really need it. What good is optimizing for code speed right now if the very act of optimizing for code speed significantly contributes to me ultimately giving up on the project? Not much.

TL;DR Premature optimization (for computational speed) is the root of all evil.

Welp, see you later.
